# Facial_Emotion_Recognition_using_CNN
This project is a Facial Emotion Recognition system developed using a Convolutional Neural Network (CNN) model. It can identify a range of human emotions from facial expressions captured in images, making it suitable for various applications, such as human-computer interaction, mental health monitoring, and more.

**Project Structure**
FER.ipynb: Jupyter notebook with code for loading data, building the CNN model, training, evaluation, and prediction.
model.h5: Saved model file (HDF5 format) for easy loading and deployment.
config.json: JSON file containing model configuration, data preprocessing details, and hyperparameters.
Features
**Emotion Detection **: Detects primary emotions such as happiness, sadness, anger, surprise, and neutral.
Data Preprocessing: Preprocessing steps for face detection, resizing, and normalization.
Model Architecture: Utilizes a CNN architecture optimized for feature extraction and classification tasks.
Live Video Emotion Detection: After training the final model, it can detect emotions in real-time from a live video feed or webcam input.
Evaluation Metrics: Tracks accuracy, loss, and confusion matrix to assess model performance.
